{"name":"Skrap","tagline":"Easily scrap web pages by providing json recipes","body":"# skrap\r\n\r\n**Skrap** is a command line utility and node.js module for easily scraping web pages by providing [json recipes](#create-a-recipe).\r\n\r\n## Getting Started\r\nInstall the module with: `npm install skrap`\r\n\r\n### Use it from the command line\r\n\r\n    skrap recipe.json param1=value param2=value ... [options]\r\n\r\n### Use it in node.js\r\n\r\n```javascript\r\nvar skrap = require('skrap');\r\nvar recipePath = \"./recipe.json\";\r\n\r\nskrap(recipePath, {param: 'value'}, function(data) {\r\n  \tconsole.log(data);\r\n})\r\n```\r\n\r\n## Documentation\r\n\r\n### Create a recipe\r\nA recipe is just a JSON file that contains rules for scraping a web page. Here's a simple example:\r\n\r\n```json\r\n{\r\n    \"url\" : \"http://www.imdb.com/find?q=${movie}&s=tt&ttype=ft&ref_=fn_ft\",\r\n    \"collections\" : [{\r\n        \"name\" : \"movies\",\r\n        \"query\": \"$('table.findList tr')\",\r\n        \"fields\": {\r\n            \"title\" : \"find('td.result_text a').text()\",\r\n            \"year\" : \"find('td.result_text').text().match(/\\\\((\\\\d{4})\\\\)/)[1]\",\r\n            \"poster\" : \"find('td.primary_photo img').attr('src')\",\r\n        }\r\n    }]\r\n}\r\n```\r\n\r\nThe recipe makes use of CSS selectors for targeting the pieces of data that needs to be scraped. **Skrap** depends on the [`cheerio`](https://github.com/MatthewMueller/cheerio) node.js module for querying the DOM, which [selector's implementation](https://github.com/MatthewMueller/cheerio#selectors) is nearly identical to jQuery's, so the API is very similar.\r\n\r\n#### Brakedown of a simple recipe file\r\n\r\n* `url` - the url of the page that needs to pe scraped, can contain multiple placeholders in the form of `${param_name}` for paramters that can be passed from the command line or programtically in node.js\r\n* `collections` - an array of objects that describe one or more collections (lists of data) to be parsed from the page\r\n    - `name` - the collection's name for grouping the results in the output\r\n    - `query` - the selector function that should return an array of objects from which to build the collection\r\n    - `fields` - pairs of data field names and function calls to be applied on the queried objects for retriving the pieces of data needed\r\n\r\nRunning `skrap` with the above example and passing the parameter `movie=spider-man` will generate [this JSON file](https://gist.github.com/nickdima/8898038)\r\n\r\n#### Page crawling and advanced options\r\n\r\nHere's a more complex example:\r\n\r\n```json\r\n{\r\n    \"url\" : \"http://www.imdb.com/find?q=${movie}&s=tt&ttype=ft&ref_=fn_ft\",\r\n    \"headers\": {\r\n        \"Accept-Language\": \"en-US,en;q=0.8,it;q=0.6,ro;q=0.4\"\r\n    },\r\n    \"collections\" : [{\r\n        \"name\" : \"movies\",\r\n        \"query\": \"$('table.findList tr')\",\r\n        \"fields\": {\r\n            \"title\" : \"find('td.result_text a').text()\",\r\n            \"year\" : \"find('td.result_text').text().match(/\\\\((\\\\d{4})\\\\)/)[1]\",\r\n            \"poster\" : \"find('td.primary_photo img').attr('src')\",\r\n            \"details\": {\r\n                \"url\" : \"find('td.result_text a').attr('href').replace('/','http://www.imdb.com/')\",\r\n                \"group\": false,\r\n                \"fields\": {\r\n                    \"rating\": \"$('#overview-top .star-box-giga-star').text().trim()\",\r\n                    \"duration\": \"$('#overview-top time').text().trim()\"             \r\n                }\r\n            }\r\n        }\r\n    }]\r\n}\r\n```\r\n\r\n**Optional fields:**\r\n\r\n* `headers` - key, value pairs of http headers to be passed when making the requests for the pages to be scraped\r\n\r\n**Page crawling**\r\n\r\n**Skrap** has basic support for one level deep page crawling. The way it works is by provinding an object with crawling instructions instead of just a selector for a field name.\r\n* `url` - the url of the page that needs to be crawled, a function call simmilar to the ones for retriving the pieces of data\r\n* `group` - a boolean value for specifing if the crawled data should be grouped under an object (using the parent field name) or attached to the main object. Defaults to `true`\r\n* `fields` - pairs of data field names and selector functions for retriving the pieces of data needed\r\n\r\nIn cases when you need to crawl a page for just a single piece of data, there's also a simplified syntax:\r\n\r\n```json\r\n\"rating\": {\r\n    \"url\" : \"find('td.result_text a').attr('href').replace('/','http://www.imdb.com/')\",\r\n    \"query\": \"$('#overview-top .star-box-giga-star').text().trim()\"\r\n}\r\n```\r\n\r\n## Examples\r\nSee the [/examples](https://github.com/nickdima/skrap/tree/master/examples) folder\r\n\r\n## Contributing\r\nIn lieu of a formal styleguide, take care to maintain the existing coding style.\r\n\r\n## License\r\nCopyright (c) 2014 Nick Dima  \r\nLicensed under the MIT license.\r\n","google":"UA-47905952-1","note":"Don't delete this file! It's used internally to help with page regeneration."}